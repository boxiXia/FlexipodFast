# note: for training flexipod
defaults:
    - agent: sac

seed: 1

agent:
    critic_cfg:
        hidden_channels: [512,256,256,256]
        # hidden_dim: 256
        # hidden_depth: 4
    actor_cfg:
        hidden_channels: [512,256,256,256]
        # hidden_dim: 256
        # hidden_depth: 4
    # batch_size: 512
    batch_size: 1024
    discount: 0.999
    # batch_size: 256
    critic_target_update_frequency: 1
    # critic_tau: 0.005
    critic_tau: 0.008

update_frequency: 16 #num of update is devided by this number


load_model: False
# load_model: D:\\repo\\FlexipodFast\\src\\py_src\\exp\\model\\14140373_5727.chpt
# load_model: D:\\repo\\FlexipodFast\\src\\py_src\\exp\\model\\9460682_617.chpt
# load_model: D:\\repo\\FlexipodFast\\src\\py_src\\exp\\model\\7980571_640.chpt
# load_model: D:\\repo\\FlexipodFast\\src\\py_src\\exp\\model\\1576903_9999.chpt
train: True
# train: False

num_saved_model: 20 # saving the top x models

num_seed_steps: 40000

eval_frequency: 10000
num_eval_episodes: 1

# env:
#     _target_: dmc2gym.make
#     domain_name: cheetah
#     task_name: run
#     seed: ${seed}
#     visualize_reward: True
env:
    _target_: flexipod_env.make
    humanoid_task: True
    # humanoid_task: False



# this needs to be specified manually
experiment: test_exp

num_train_steps: 2e7
replay_buffer_capacity: 1e7
replay_buffer_save_interval: 5e6 # save every this step

# replay_buffer_capacity: ${num_train_steps}


device: "cuda"

# logger
log_frequency: 10000
log_save_tb: true

# video recorder
save_video: False
# save_video: true

# hydra configuration
hydra:
    job:
        # name: sac
        name: ${agent.name}
    run:
        dir: ./exp/${train}_${now:%Y.%m.%d.%H%M}
    searchpath:
        - pkg://pytorch_sac/config
