# note: for training flexipod
# to eval: python train.py num_eval_episodes=100 train=False env.max_episode_steps=20000 load_model=...

defaults:
    - agent: sac
    - _self_

seed: 1

agent:
    critic_cfg:
        hidden_channels: [512,256,256,256]
    actor_cfg:
        hidden_channels: [512,256,256,256]
    batch_size: 1024
    discount: 0.999 # discount factor
    critic_target_update_frequency: 2
    # critic_tau: 0.01
    # critic_tau: 0.008
    critic_tau: 0.005


update_frequency: 16 #num of update is devided by this number


load_model: False
load_replay_buffer: False
# load_model: D:\\repo\\FlexipodFast\\src\\py_src\\exp\\model\\3814408_22475.chpt
train: True

num_saved_model: 50 # saving the top x models

num_seed_steps: 40000

eval_frequency: 10000
num_eval_episodes: 1

# env:
#     _target_: dmc2gym.make
#     domain_name: cheetah
#     task_name: run
#     seed: ${seed}
#     visualize_reward: True
env:
    _target_: flexipod_env.make
    # _target_: .real_env.physical_env.PhysicalHumanoid
    humanoid_task: True
    max_episode_steps: 2000
    # humanoid_task: False



# this needs to be specified manually
experiment: test_exp

num_train_steps: 2e7

replay_buffer:
    # capacity: 5e6
    capacity: 1e7
    n_step: 5 # nstep target


replay_buffer_save_interval: ${eval_frequency} # save every this step


device: "cuda"

# logger
log_frequency: 10000
log_save_tb: true

# video recorder
save_video: False
# save_video: true

# hydra configuration
hydra:
    job:
        # name: sac
        name: ${agent.name}
    run:
        dir: ./exp/${train}_${now:%Y.%m.%d.%H%M}
    searchpath:
        - pkg://pytorch_sac/config
